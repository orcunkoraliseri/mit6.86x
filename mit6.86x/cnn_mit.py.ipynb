{
  "cells":[
    {
      "cell_type":"code",
      "source":[
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#device configuration \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyper-params\n",
        "num_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate = 0.01\n",
        "\n",
        "# PILImage images range [0, 1]\n",
        "# transform tensors to [-1, 1] \n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), \n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='.\/data', train=True,\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='.\/data', train=True,\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "clases = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'horse', 'ship', 'truck')"
      ],
      "execution_count":12,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "#implement cnn\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self,x):\n",
        "        pass\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4,3,32,32]= 4,3,1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs= model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()"
      ],
      "execution_count":13,
      "outputs":[
        {
          "ename":"ModuleAttributeError",
          "evalue":"ModuleAttributeError: 'ConvNet' object has no attribute '_modules'",
          "traceback":[
            "\u001b[0;31m---------------------------------------------------------------------------",
            "Traceback (most recent call last)",
            "    at line 9 in <module>",
            "ModuleAttributeError: 'ConvNet' object has no attribute '_modules'"
          ],
          "output_type":"error"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        
      ],
      "execution_count":0,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}